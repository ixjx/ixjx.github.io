<!DOCTYPE html>
<html>

<head>
    <title>pytorch学习13-使用RNN优化流量预测</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="keywords" content="pytorch学习13-使用RNN优化流量预测, pytorch, AI, CodeShurrik" />
    <meta name="description" content="pytorch学习13-使用RNN优化流量预测, pytorch, AI, 前面《pytorch学习10-流量预测实战》对流量的预测，停留在使用稠密网络（DNN），输入是当时影响流量的特征值，实质上是计算出来一种非线性空间变换，以此来推理出当时的流量。" />
    <meta name="theme-color" content="#2CA6CB"/>
    <meta name="google-adsense-account" content="ca-pub-8989608156149583">
    <link rel="shortcut icon" type="image/x-icon" media="screen" href="http://localhost:4000/favicon.ico" />
    <link rel="canonical" href="http://localhost:4000/2022-10-16/pytorch%E5%AD%A6%E4%B9%A013-%E4%BD%BF%E7%94%A8RNN%E4%BC%98%E5%8C%96%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/" />
    <link rel="alternate" type="application/rss+xml" title="CodeShurrik" href="http://localhost:4000/feed.xml"  />

    <link rel="stylesheet" type="text/css" href="http://localhost:4000/static/css/bootstrap.css"/>
    <link rel="stylesheet" href="https://cdn.bootcss.com/octicons/3.5.0/octicons.min.css" >
    <!-- <script async defer data-website-id="bef53d4f-2117-4edd-b7a8-8754ea01f2c2" src="http://localhost:4000/static/js/umami.js"></script> -->
    <link rel="stylesheet" type="text/css" href="http://localhost:4000/static/css/style.css" />
    <link rel="stylesheet" type="text/css" href="http://localhost:4000/static/css/highlight.css" />
    <link rel="stylesheet" type="text/css" href="http://localhost:4000/static/css/post.css" />
    
</head>


<body>

    <header>
        <nav class="navbar navbar-tiffany rectangle" role="navigation">
            <div class="container">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="http://localhost:4000/">CodeShurrik</a>
                    <p class="navbar-text">
                        <span id="typed"></span>
                        <script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.9"></script>
                        <script>
                            var typed = new Typed("#typed", {
                                strings: ['welcome to','shurrik blog'],
                                startDelay: 300,
                                typeSpeed: 100,
                                loop: true,
                                backSpeed: 50,
                                showCursor: true
                            });
                        </script>
                    </p>
                </div>
                <div class="collapse navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        
                        <li>
                        <a href="http://localhost:4000/" class="word-keep"><span class="octicon octicon-home"></span></span>&nbsp;&nbsp;Blog</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/category/" class="word-keep"><span class="octicon octicon-list-unordered"></span>&nbsp;&nbsp;Category</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/tags/" class="word-keep"><span class="octicon octicon-tag"></span>&nbsp;&nbsp;Tag</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/ref/" class="word-keep"><span class="octicon octicon-file-code"></span>&nbsp;&nbsp;Ref</a>
                        </li>
                        
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/shell/" class="word-keep"><span class="octicon octicon-terminal"></span>&nbsp;&nbsp;Shell</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/about/" class="word-keep"><span class="octicon octicon-thumbsup"></span>&nbsp;&nbsp;About</a>
                        </li>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                    </ul>
                </div>
            </div>
        </nav>
    </header>



<div class="main">
    <div class="container">
        <div class="row">
    <div class="content col-lg-9">
        <div class="sheet post">
          <header>
            <h2>pytorch学习13-使用RNN优化流量预测</h2>
            <p class="post-meta">
                <span class="octicon octicon-clock"></span> Oct 16, 2022
            </p>
            <p class="post-tag">
                <span><a href="http://localhost:4000/category/#pytorch"><span class="octicon octicon-list-unordered"></span>&nbsp;pytorch</a></span>
                <span>
                    <a class="word-keep" href="http://localhost:4000/tags/#AI"><span class="octicon octicon-tag"></span>&nbsp;AI</a>
                    
                </span>
            </p>
          </header>
          <hr class="boundary">
          <article>
            <p>前面<a href="https://ixjx.github.io/blog/2022-09-30/pytorch%E5%AD%A6%E4%B9%A010-%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B%E5%AE%9E%E6%88%98/">《pytorch学习10-流量预测实战》</a>对流量的预测，停留在使用稠密网络（DNN），输入是当时影响流量的特征值，实质上是计算出来一种<strong>非线性空间变换</strong>，以此来推理出当时的流量。</p>

<p>这其实有一个很大的矛盾，我都能获取<strong>当时的特征</strong>了，自然也能获取<strong>当时的流量</strong>。所以推理出的流量只能用于和实际流量对比，并不能实现”预测”的能力。</p>

<p>学习循环神经网络后，通过把历史数据做成序列化数据喂给RNN模型，输出的数据受前一个序列影响，自然想到可以利用RNN来实现真正的”预测”能力。</p>

<p>更新1：看了下<a href="https://zh-v2.d2l.ai/">李沐老师的教程</a>，发现之前的预测方式有点问题。RNN分为单步预测（one-step-ahead prediction）、和”K步预测”。</p>

<p>单步预测往往比较精确，而K步预测经过几个预测步骤之后，预测的结果很快就会衰减到一个常数，这是因为错误的积累（可以参考1.01^365）。例如，未来24小时的天气预报往往相当准确， 但超过这个时间，精度就会迅速下降。</p>

<p>针对这一点，我暂时想出的方法是将输入维度由1改为144（即6 * 24），输出维度也相应改为144，即一天的数据量。这样仅仅是增大训练的数据量就行了。同时为了减少预测数据滞后于真实数据，利用流量数据的周期性，计算出当前时间步过去一天的流量均值加入特征。</p>

<h3 id="rnn模型建立"><strong>RNN模型建立</strong></h3>

<p>RNN天然适用于序列数据建模，这里我选用GRU，num_layers=3，bidirectional=False。在最后时刻输出的隐藏状态hn的基础上，使用一个全连接得到预测输出。模型如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">HIDDEN_SIZE</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">GRU</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span><span class="p">,</span>
                                <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">NUM_LAYERS</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">HIDDEN_SIZE</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">OUTPUT_SIZE</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>                      <span class="c1"># x.shape(batch_size, seq_len, input_size)
</span>        <span class="c1"># hidden = torch.zeros(NUM_LAYERS, x.shape[0], HIDDEN_SIZE)  # out.shape(b,s,h)  hidden.shape(num_layers, batch_size, hidden_size)
</span>        <span class="n">out</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gru</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">ln</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>  <span class="c1"># =hidden[-1]
</span>        <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
</code></pre></div></div>

<h3 id="数据采集与处理"><strong>数据采集与处理</strong></h3>

<p>数据处理方式差不多，只是需要把输入x的维度调整为(batch_size, seq_len, input_size)，这里的batch_size注意和DataLoader里的batch_size不是一回事，RNN的batch_size指样本数量。假设某天的数据受前7天的影响，所以序列长度seq_len取7。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RNNTrainDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">np_data</span><span class="p">):</span>
        <span class="c1"># 生成序列数据
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">extract_data</span><span class="p">(</span><span class="n">np_data</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># shape(n, seq_len, INPUT_SIZE)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">y_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">OUTPUT_SIZE</span><span class="p">)</span>    <span class="c1">#shape(n, OUTPUT_SIZE)
</span>
        <span class="c1"># 获得reshape后数据集行数n, 即batch_size
</span>        <span class="n">self</span><span class="p">.</span><span class="nb">len</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">x_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">extract_data</span><span class="p">(</span><span class="n">np_data</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">):</span>  <span class="c1"># 序列为7天的数据,取x:7 , y:1
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">np_data</span><span class="p">)</span> <span class="o">-</span> <span class="n">seq_len</span><span class="p">):</span>
            <span class="n">x</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np_data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="p">])</span>
            <span class="n">y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np_data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># 获得索引方法
</span>    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">x_data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">y_data</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="c1"># 获得数据集长度
</span>    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nb">len</span>
</code></pre></div></div>

<h3 id="训练"><strong>训练</strong></h3>

<p>训练还是那3板斧，只是优化器换成<code class="language-plaintext highlighter-rouge">Adam</code>。</p>

<p>整体代码</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">django.db.models.query</span> <span class="kn">import</span> <span class="n">QuerySet</span>
<span class="kn">from</span> <span class="n">.models</span> <span class="kn">import</span> <span class="n">ThpDataset</span>

<span class="c1"># plt.style.use('seaborn-whitegrid')
# 显示中文
</span><span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="sh">'</span><span class="s">font.sans-serif</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">SimHei</span><span class="sh">'</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="sh">'</span><span class="s">axes.unicode_minus</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1">#RNN模型参数
</span><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="mi">144</span>
<span class="n">HIDDEN_SIZE</span> <span class="o">=</span> <span class="mi">288</span>
<span class="n">OUTPUT_SIZE</span> <span class="o">=</span> <span class="mi">144</span>
<span class="n">SEQ_LEN</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">NUM_LAYERS</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1">#RNN训练参数
</span><span class="n">EPOCH</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">RATIO</span> <span class="o">=</span> <span class="mf">0.87</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda:0</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">thpdataset_lines</span><span class="p">):</span>
    <span class="c1"># 数据载入预处理
</span>    <span class="k">assert</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">thpdataset_lines</span><span class="p">,</span> <span class="n">QuerySet</span><span class="p">),</span> <span class="sh">'</span><span class="s">原始数据需传入QuerySet</span><span class="sh">'</span>
    <span class="c1"># 组装原始数据，列表
</span>    <span class="n">src_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">thpdataset_line</span><span class="p">.</span><span class="n">thp</span> <span class="k">for</span> <span class="n">thpdataset_line</span> <span class="ow">in</span> <span class="n">thpdataset_lines</span><span class="p">]</span>

    <span class="c1"># 列表转换为数组
</span>    <span class="n">np_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">src_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">np_data</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">np_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="n">INPUT_SIZE</span><span class="p">)</span><span class="o">*</span><span class="n">INPUT_SIZE</span><span class="p">:]</span>  <span class="c1">#取整
</span>    
    <span class="c1"># 一维数组数组转换为矩阵, (n,144)
</span>    <span class="n">np_data</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">INPUT_SIZE</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np_data</span>


<span class="k">def</span> <span class="nf">normalize_data</span><span class="p">(</span><span class="n">np_data</span><span class="p">):</span>
    <span class="c1"># 计算训练数据集的最大最小值
</span>    <span class="nb">max</span><span class="p">,</span> <span class="nb">min</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np_data</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># 记录训练数据的归一化参数，在预测时对数据做反归一化
</span>    <span class="n">np</span><span class="p">.</span><span class="nf">savez</span><span class="p">(</span><span class="sh">'</span><span class="s">deeplearn/rnn_train_param.npz</span><span class="sh">'</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">)</span>
    <span class="c1"># 对数据进行归一化处理
</span>    <span class="n">norm_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">np_data</span> <span class="o">-</span> <span class="nb">min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">max</span> <span class="o">-</span> <span class="nb">min</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">norm_data</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="nb">min</span>


<span class="k">class</span> <span class="nc">RNNTrainDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">np_data</span><span class="p">):</span>
        <span class="c1"># 生成序列数据
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">extract_data</span><span class="p">(</span><span class="n">np_data</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># shape(n, seq_len, INPUT_SIZE)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">y_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">OUTPUT_SIZE</span><span class="p">)</span>    <span class="c1">#shape(n, OUTPUT_SIZE)
</span>
        <span class="c1"># 获得reshape后数据集行数n, 即batch_size
</span>        <span class="n">self</span><span class="p">.</span><span class="nb">len</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">x_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">extract_data</span><span class="p">(</span><span class="n">np_data</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">SEQ_LEN</span><span class="p">):</span>  <span class="c1"># 序列为7天的数据,取x:7 , y:1
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">np_data</span><span class="p">)</span> <span class="o">-</span> <span class="n">seq_len</span><span class="p">):</span>
            <span class="n">x</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np_data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="p">])</span>
            <span class="n">y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np_data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># 获得索引方法
</span>    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">x_data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">y_data</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="c1"># 获得数据集长度
</span>    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nb">len</span>


<span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">HIDDEN_SIZE</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span><span class="p">,</span>
                                <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">NUM_LAYERS</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">HIDDEN_SIZE</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">OUTPUT_SIZE</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>                      <span class="c1"># x.shape(batch_size, seq_len, input_size)
</span>        <span class="c1"># hidden = torch.zeros(NUM_LAYERS, x.shape[0], HIDDEN_SIZE)  # out.shape(b,s,h)  hidden.shape(num_layers, batch_size, hidden_size)
</span>        <span class="n">out</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gru</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">ln</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>  <span class="c1"># =hidden[-1]
</span>        <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>


<span class="c1"># 模型
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">RNNModel</span><span class="p">()</span>
<span class="c1"># 损失函数
</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>
<span class="c1"># 优化器
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
<span class="c1"># 学习率调整器 adam不需手动调整学习率
# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
#     optimizer=optimizer, verbose=True)
</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="c1"># 读取训练数据并划分训练集和测试集
</span>    <span class="n">now</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">()</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="n">datetime</span><span class="p">.</span><span class="nf">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">thpdataset_lines</span> <span class="o">=</span> <span class="n">ThpDataset</span><span class="p">.</span><span class="n">objects</span><span class="p">.</span><span class="nf">filter</span><span class="p">(</span>
        <span class="n">created_at__gte</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">created_at__lte</span><span class="o">=</span><span class="n">now</span><span class="p">)</span>
    
    <span class="n">np_data</span> <span class="o">=</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">thpdataset_lines</span><span class="p">)</span>
    <span class="n">norm_data</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="nb">min</span> <span class="o">=</span> <span class="nf">normalize_data</span><span class="p">(</span><span class="n">np_data</span><span class="p">)</span>

    <span class="n">offset</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">norm_data</span><span class="p">)</span><span class="o">*</span><span class="n">RATIO</span><span class="p">)</span>
    <span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">norm_data</span><span class="p">[:</span><span class="n">offset</span><span class="p">],</span> <span class="n">norm_data</span><span class="p">[</span><span class="n">offset</span><span class="p">:]</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="nc">RNNTrainDataset</span><span class="p">(</span><span class="n">norm_data</span><span class="p">)</span>
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="nc">RNNTrainDataset</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span> 

    <span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span>
                             <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="p">[:]</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">[</span><span class="si">{</span><span class="n">now</span><span class="si">}</span><span class="s">]RNN训练开始，seq训练集长度为:</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1"># 加载训练模型
</span>    <span class="c1"># if os.path.exists('deeplearn/rnn_model_param3.pkl'):
</span>    <span class="c1">#     model.load_state_dict(torch.load('deeplearn/rnn_model_param3.pkl'))
</span>    <span class="n">train_loss</span><span class="p">,</span> <span class="n">test_loss</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">EPOCH</span><span class="p">):</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c1"># 准备数据dataloader会将按batch_size返回的数据整合成矩阵加载
</span>            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">NUM_LAYERS</span><span class="p">,</span> <span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">HIDDEN_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># 前馈
</span>            <span class="n">y_pred</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="c1"># if epoch % 100 == 0:
</span>            <span class="c1">#     print(epoch, i, loss.item())
</span>            <span class="c1"># 反向传播求梯度
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="c1"># 更新
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        <span class="n">train_loss</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
        <span class="c1"># 调整学习率
</span>        <span class="c1"># scheduler.step(loss.item())
</span>
        <span class="c1"># 测试
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">NUM_LAYERS</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">HIDDEN_SIZE</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">y_pred</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>  
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">test_loss</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>

    <span class="c1"># 保存模型参数
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">))</span>
    <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="sh">'</span><span class="s">deeplearn/rnn_model_param3.pkl</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">[</span><span class="si">{</span><span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">()</span><span class="si">}</span><span class="s">]RNN模型保存完毕</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="c1"># 对测试结果做反归一化处理
</span>    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">RNN测试开始，seq测试集长度为:</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="nb">max</span> <span class="o">-</span> <span class="nb">min</span><span class="p">)</span> <span class="o">+</span> <span class="nb">min</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="nb">max</span> <span class="o">-</span> <span class="nb">min</span><span class="p">)</span> <span class="o">+</span> <span class="nb">min</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">*</span><span class="mi">8</span><span class="o">/</span><span class="mi">1000</span><span class="o">/</span><span class="mi">1000</span><span class="o">/</span><span class="mi">1000</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">*</span><span class="mi">8</span><span class="o">/</span><span class="mi">1000</span><span class="o">/</span><span class="mi">1000</span><span class="o">/</span><span class="mi">1000</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">RNN训练数据</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">实际流量</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_pred</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">预测流量</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">流量,Gb/s</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">train_loss</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">test_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">test_loss</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">误差值</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">'</span><span class="s">deeplearn/rnn_test.png</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/4729226/196327886-38f08c42-3706-458a-9195-2a49ba75617d.png" alt="微信截图_20221018101816" /></p>


          </article>
          <hr class="boundary">
          <div id="post-share" class="bdsharebuttonbox">
              <a href="#" class="bds_more" data-cmd="more"></a>
              <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
              <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
              <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
              <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
              <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
          </div>
        </div>
        <div class="pad-min"></div>
       <!-- <div id="post-comment" class="sheet post"> -->
        <!--PC和WAP自适应版-->
        <!-- <div id="SOHUCS" ></div>  -->
        <!-- <script type="text/javascript"> 
        (function(){ 
        var appid = 'cyt71nso6'; 
        var conf = 'prod_d224308500d6b59d843a38fa4a3b0fd9'; 
        var width = window.innerWidth || document.documentElement.clientWidth; 
        if (width < 960) { 
        window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>'); } else { var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})}); } })(); </script>

        <div id="disqus_thread"></div> -->
        <!-- </div> -->
    </div>
    <div class="content-navigation col-lg-3">
      <div class="shadow-bottom-center" >
        <div class="content-navigation-toc">
            <div class="content-navigation-header">
                <span class="octicon octicon-list-unordered"></span>&nbsp;Toc
            </div>
            <div class="content-navigation-list toc"></div>
        </div>
        <div class="content-navigation-tag">
            <div class="content-navigation-header">
                <span class="octicon octicon-list-unordered"></span>&nbsp;Tags
            </div>
            <div class="content-navigation-list">
                <ul>
                    
                    <li>
                        <a href="http://localhost:4000/tags#AI"><span class="octicon octicon-tag"></span>&nbsp;AI</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <div class="content-navigation-related">
            <div class="content-navigation-header">
                <span class="octicon octicon-list-unordered"></span>&nbsp;Related
            </div>
            <div class="content-navigation-list">
                <ul>
                    

                    

                    
                        
                            <li>
                                <a href="http://localhost:4000/2023-01-03/pytorch%E5%AD%A6%E4%B9%A016-transformer%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/">pytorch学习16-transformer流量预测</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-12-03/pytorch%E5%AD%A6%E4%B9%A015-%E5%8A%A0%E5%85%A5%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84seq2seq%E4%BC%98%E5%8C%96%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/">pytorch学习15-加入注意力机制的seq2seq优化流量预测</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-11-09/pytorch%E5%AD%A6%E4%B9%A014-%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83/">pytorch学习14-使用GPU训练</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-10-14/pytorch%E5%AD%A6%E4%B9%A012-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/">pytorch学习12-循环神经网络基础</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-10-09/pytorch%E5%AD%A6%E4%B9%A011-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/">pytorch学习11-卷积神经网络基础</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-30/pytorch%E5%AD%A6%E4%B9%A010-%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B%E5%AE%9E%E6%88%98/">pytorch学习10-流量预测实战</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-29/pytorch%E5%AD%A6%E4%B9%A09-%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/">pytorch学习9-多分类问题</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-27/pytorch%E5%AD%A6%E4%B9%A08-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/">pytorch学习8-加载数据集</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-26/pytorch%E5%AD%A6%E4%B9%A07-%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81%E7%9A%84%E8%BE%93%E5%85%A5/">pytorch学习7-处理多维特征的输入</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-23/pytorch%E5%AD%A6%E4%B9%A06-%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98Logistic%E5%9B%9E%E5%BD%92/">pytorch学习6-分类问题Logistic回归</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-22/pytorch%E5%AD%A6%E4%B9%A05-pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">pytorch学习5-pytorch实现线性回归</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-21/pytorch%E5%AD%A6%E4%B9%A04-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/">pytorch学习4-反向传播</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-20/pytorch%E5%AD%A6%E4%B9%A03-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">pytorch学习3-梯度下降算法</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-15/pytorch%E5%AD%A6%E4%B9%A02-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/">pytorch学习2-线性模型</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-13/pytorch%E5%AD%A6%E4%B9%A01-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/">pytorch学习1-人工智能基础</a>
                            </li>
                        
                    
                </ul>
            </div>
        </div>
      </div>
    </div>
</div>
    </div>
    
    <div class="page-scrollTop" data-toggle="tooltip" data-placement="top" title="Top">
        <a href="javascript:void(0);">
            <div class="arrow"></div>
            <div class="stick"></div>
        </a>
    </div>
</div>

    <footer  class="footnote footnote-tiffany">
        <div class="container">
                <a class="foot-item" href="mailto:shurrik.dly@gmail.com" target="_blank"><span class="octicon octicon-mail"></span></a>
                <a class="foot-item" href="https://github.com/ixjx" target="_blank"><span class="octicon octicon-mark-github"></span></a>
                <a class="foot-item" href="http://localhost:4000/feed.xml" target="_blank"><span class="octicon octicon-rss"></span></a>
                <a class="foot-item" href="http://localhost:4000/link/"><span class="octicon octicon-link-external"></span></a>
                &nbsp;
                <a href="https://ixjx.github.io/"><span class="word-keep">&copy; Codeshurrik</span></a>
                <br>
                <span>珍爱生命，远离IE。请使用Chrome或Safari，你懂的 :)</span>
                <br>
                <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
                <script>// <![CDATA[
                    var now = new Date(); function createtime(){ var grt= new Date("07/28/2013 21:00:00");now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} document.getElementById("timeDate").innerHTML = "已安全运行"+dnum+"天"; document.getElementById("times").innerHTML = hnum + "小时" + mnum + "分" + snum + "秒"; } setInterval("createtime()",250);
                // ]]></script>
        </div>
    </footer>
    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script>
    <script type="text/javascript" src="https://cdn.bootcss.com/bootstrap/3.3.0/js/bootstrap.min.js"></script>
    <!-- <script id="MathJax-script" async src="https://cdn.bootcss.com/mathjax/3.0.5/es5/tex-mml-chtml.js"></script> -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    
    <script type="text/javascript" src="http://localhost:4000/static/js/script.js"></script>
    <script type="text/javascript" src="http://localhost:4000/static/js/post.js"></script>
    


</body>
</html>
