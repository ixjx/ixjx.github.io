<!DOCTYPE html>
<html>

<head>
    <title>pytorch学习4-反向传播</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="keywords" content="pytorch学习4-反向传播, pytorch, AI, CodeShurrik" />
    <meta name="description" content="pytorch学习4-反向传播, pytorch, AI, 在前篇的线性模型中" />
    <meta name="theme-color" content="#2CA6CB"/>
    <link rel="shortcut icon" type="image/x-icon" media="screen" href="http://localhost:4000/favicon.ico" />
    <link rel="canonical" href="http://localhost:4000/2022-09-21/pytorch%E5%AD%A6%E4%B9%A04-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/" />
    <link rel="alternate" type="application/rss+xml" title="CodeShurrik" href="http://localhost:4000/feed.xml"  />

    <link rel="stylesheet" type="text/css" href="http://localhost:4000/static/css/bootstrap.css"/>
    <link rel="stylesheet" href="https://cdn.bootcss.com/octicons/3.5.0/octicons.min.css" >
    <!-- <script async defer data-website-id="bef53d4f-2117-4edd-b7a8-8754ea01f2c2" src="http://localhost:4000/static/js/umami.js"></script> -->
    <link rel="stylesheet" type="text/css" href="http://localhost:4000/static/css/style.css" />
    <link rel="stylesheet" type="text/css" href="http://localhost:4000/static/css/highlight.css" />
    <link rel="stylesheet" type="text/css" href="http://localhost:4000/static/css/post.css" />
    
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8989608156149583"
     crossorigin="anonymous"></script>
</head>


<body>

    <header>
        <nav class="navbar navbar-tiffany rectangle" role="navigation">
            <div class="container">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="http://localhost:4000/">CodeShurrik</a>
                    <p class="navbar-text">
                        <span id="typed"></span>
                        <script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.9"></script>
                        <script>
                            var typed = new Typed("#typed", {
                                strings: ['welcome to','shurrik blog'],
                                startDelay: 300,
                                typeSpeed: 100,
                                loop: true,
                                backSpeed: 50,
                                showCursor: true
                            });
                        </script>
                    </p>
                </div>
                <div class="collapse navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        
                        <li>
                        <a href="http://localhost:4000/" class="word-keep"><span class="octicon octicon-home"></span></span>&nbsp;&nbsp;Blog</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/category/" class="word-keep"><span class="octicon octicon-list-unordered"></span>&nbsp;&nbsp;Category</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/tags/" class="word-keep"><span class="octicon octicon-tag"></span>&nbsp;&nbsp;Tag</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/fm/" class="word-keep"><span class="octicon octicon-unmute"></span>&nbsp;&nbsp;FM</a>
                        </li>
                        
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/shell/" class="word-keep"><span class="octicon octicon-terminal"></span>&nbsp;&nbsp;Shell</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="http://localhost:4000/about/" class="word-keep"><span class="octicon octicon-thumbsup"></span>&nbsp;&nbsp;About</a>
                        </li>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                    </ul>
                </div>
            </div>
        </nav>
    </header>



<div class="main">
    <div class="container">
        <div class="row">
    <div class="content col-lg-9">
        <div class="sheet post">
          <header>
            <h2>pytorch学习4-反向传播</h2>
            <p class="post-meta">
                <span class="octicon octicon-clock"></span> Sep 21, 2022
            </p>
            <p class="post-tag">
                <span><a href="http://localhost:4000/category/#pytorch"><span class="octicon octicon-list-unordered"></span>&nbsp;pytorch</a></span>
                <span>
                    <a class="word-keep" href="http://localhost:4000/tags/#AI"><span class="octicon octicon-tag"></span>&nbsp;AI</a>
                    
                </span>
            </p>
          </header>
          <hr class="boundary">
          <article>
            <p>在前篇的线性模型中</p>

\[\widehat y = \omega x\]

<p>如果以神经网络的视角代入来看，则x为<strong>输入层</strong>，即input层，ω为<strong>权重</strong>，y^为<strong>输出层</strong>。在神经网络中，通常将ω以及<code class="language-plaintext highlighter-rouge">*</code>计算操作的部分合并看做一个神经元（层）。而神经网络的训练过程即为更新ω的过程，其更新的情况依赖于
\(\frac{\partial loss}{\partial \omega}\)
，而并非
\(\frac{\partial \widehat y}{\partial \omega}\)</p>

<p><img src="https://user-images.githubusercontent.com/4729226/191438054-7a0933d6-899c-4599-aa2c-62ca30a3cdf6.png" alt="image-20210301201835811" /></p>

<p>然而，对于复杂模型而言求解过程就复杂很多。在图示的神经网络中，每个结点为一个神经元，结点之间的连线为权重。</p>

<p><img src="https://user-images.githubusercontent.com/4729226/191438268-fc26273c-5c39-4fd5-859b-a30af56ec909.png" alt="image-20210301202712216" /></p>

<p>由图上可知，输入层与隐含层第一层之间就有5∗6=30个权重，隐含层的第一层与第二层之间又有6∗7=42个权重，以此类推，上图中共有30+42+49+42+30=193个权重需要计算，传统的列表达式的方式是无法完成的。</p>

<h2 id="计算图中的神经网络"><strong>计算图中的神经网络</strong></h2>

<p>在计算图中，绿色的模块为计算模块，可以在计算过程中求导。MM为矩阵乘法，ADD为加法。</p>

<p><img src="https://user-images.githubusercontent.com/4729226/191441350-758473b5-a461-415e-8331-78330a69440d.png" alt="image-20210301210756389" /></p>

<p>而上图左式中，可以化简得到如下公式</p>

\[\widehat y = W_2(W_1X+b_1)+b_2=W_2W_1X+(W_2b_1+b_2)=WX+b\]

<p>也就是说，在这个结构下单纯的增加层数，并不能增加神经网络的复杂程度，因为最后都可以化简为一个单一的神经网络。</p>

<h2 id="改进方法"><strong>改进方法</strong></h2>

<p>在每层网络结构中，增加一个非线性的变换函数（激活函数），比如<code class="language-plaintext highlighter-rouge">sigmod</code>函数</p>

<p><img src="https://user-images.githubusercontent.com/4729226/191443945-b39ed113-912b-4650-898d-2ea175b05a5f.png" alt="image-20210301211647298" /></p>

<h2 id="反向传播过程"><strong>反向传播过程</strong></h2>

<h3 id="前馈计算"><strong>前馈计算</strong></h3>

<p>在某一神经元处，输入的x与ω经过函数f(x, ω)的计算,可以获得输出值z，并继续向前以得到损失值loss.</p>

<p>在向前计算的过程中，在f(x, ω)的计算模块中会计算导数
\(\frac{\partial z}{\partial x}\)
以及
\(\frac{\partial z}{\partial \omega}\)
，并将其保存下来（在pytorch中，这样的值保存在变量x以及ω中）。</p>

<p><img src="https://user-images.githubusercontent.com/4729226/191444707-6067b2a4-1a56-409b-9b4e-97820979e7f0.png" alt="image-20210301213441765" /></p>

<h3 id="反向传播"><strong>反向传播</strong></h3>

<p>由求导的链式法则，求得loss以后，前面的神经元会将
\(\frac{\partial loss}{\partial z}\)
的值反向传播给原先的神经元，在计算单元f(x, ω)中，将得到的
\(\frac{\partial loss}{\partial x}\)
与之前存储的导数相乘，即可得到损失值对于权重以及输入层的导数，即
\(\frac{\partial loss}{\partial x}\)
，以及
\(\frac{\partial loss}{\partial \omega}\)
，基于该梯度才进行权重的调整。</p>

<p><img src="https://user-images.githubusercontent.com/4729226/191445638-c019cd00-75a1-4c7a-ad31-18a4683f0593.png" alt="image-20210301213933839" /></p>

<h1 id="pytorch中的前馈与反馈"><strong>Pytorch中的前馈与反馈</strong></h1>

<p>利用pytorch进行深度学习，最主要的是==<strong>构建计算图</strong>==</p>

<h2 id="tensor-张量"><strong>Tensor 张量</strong></h2>

<p>Tensor中重要的两个成员，<strong>data</strong>用于保存权重本身的值ω，<strong>grad</strong>用于保存损失函数对权重的导数
\(\frac{\partial loss}{\partial \omega}\)
，grad本身也是个张量。对张量进行的计算操作，都是建立计算图的过程。</p>

<p><img src="https://user-images.githubusercontent.com/4729226/191448706-e4935a34-2c1d-4c04-9415-760168b07e45.png" alt="image-20210301215917238" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x_data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]</span>

<span class="c1">#赋予tensor中的data
</span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])</span>
<span class="c1">#设定需要计算梯度grad
</span><span class="n">w</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1">#模型y=x*w 建立计算图
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="s">'''
    w为Tensor类型
    x强制转换为Tensor类型
    通过这样的方式建立计算图
    '''</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">w</span>

<span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>

<span class="k">print</span> <span class="p">(</span><span class="s">"predict  (before training)"</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">forward</span><span class="p">(</span><span class="mi">4</span><span class="p">).</span><span class="n">item</span><span class="p">())</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span><span class="n">y_data</span><span class="p">):</span>
        <span class="c1">#创建新的计算图
</span>        <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
        <span class="c1">#进行反馈计算，此时才开始求梯度，此后计算图进行释放
</span>        <span class="n">l</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1">#grad.item()取grad中的值变成标量
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">grad:'</span><span class="p">,</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">item</span><span class="p">())</span>
        <span class="c1">#单纯的数值计算要利用data，而不能用张量，否则会在内部创建新的计算图
</span>        <span class="n">w</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">w</span><span class="p">.</span><span class="n">data</span> <span class="o">-</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">w</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span>
        <span class="c1">#把权重梯度里的数据清零
</span>        <span class="n">w</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"progress:"</span><span class="p">,</span><span class="n">epoch</span><span class="p">,</span> <span class="n">l</span><span class="p">.</span><span class="n">item</span><span class="p">())</span>

<span class="k">print</span><span class="p">(</span><span class="s">"predict (after training)"</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">forward</span><span class="p">(</span><span class="mi">4</span><span class="p">).</span><span class="n">item</span><span class="p">())</span>
</code></pre></div></div>

<p>本文参考自<a href="https://www.bilibili.com/video/BV1Y7411d7Ys?p=4">B站《PyTorch深度学习实践》P4</a></p>


          </article>
          <hr class="boundary">
          <div id="post-share" class="bdsharebuttonbox">
              <a href="#" class="bds_more" data-cmd="more"></a>
              <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
              <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
              <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
              <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
              <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
          </div>
        </div>
        <div class="pad-min"></div>
       <!-- <div id="post-comment" class="sheet post"> -->
        <!--PC和WAP自适应版-->
        <!-- <div id="SOHUCS" ></div>  -->
        <!-- <script type="text/javascript"> 
        (function(){ 
        var appid = 'cyt71nso6'; 
        var conf = 'prod_d224308500d6b59d843a38fa4a3b0fd9'; 
        var width = window.innerWidth || document.documentElement.clientWidth; 
        if (width < 960) { 
        window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>'); } else { var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})}); } })(); </script>

        <div id="disqus_thread"></div> -->
        <!-- </div> -->
    </div>
    <div class="content-navigation col-lg-3">
      <div class="shadow-bottom-center" >
        <div class="content-navigation-toc">
            <div class="content-navigation-header">
                <span class="octicon octicon-list-unordered"></span>&nbsp;Toc
            </div>
            <div class="content-navigation-list toc"></div>
        </div>
        <div class="content-navigation-tag">
            <div class="content-navigation-header">
                <span class="octicon octicon-list-unordered"></span>&nbsp;Tags
            </div>
            <div class="content-navigation-list">
                <ul>
                    
                    <li>
                        <a href="http://localhost:4000/tags#AI"><span class="octicon octicon-tag"></span>&nbsp;AI</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <div class="content-navigation-related">
            <div class="content-navigation-header">
                <span class="octicon octicon-list-unordered"></span>&nbsp;Related
            </div>
            <div class="content-navigation-list">
                <ul>
                    

                    

                    
                        
                            <li>
                                <a href="http://localhost:4000/2023-01-03/pytorch%E5%AD%A6%E4%B9%A016-transformer%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/">pytorch学习16-transformer流量预测</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-12-03/pytorch%E5%AD%A6%E4%B9%A015-%E5%8A%A0%E5%85%A5%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84seq2seq%E4%BC%98%E5%8C%96%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/">pytorch学习15-加入注意力机制的seq2seq优化流量预测</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-11-09/pytorch%E5%AD%A6%E4%B9%A014-%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83/">pytorch学习14-使用GPU训练</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-10-16/pytorch%E5%AD%A6%E4%B9%A013-%E4%BD%BF%E7%94%A8RNN%E4%BC%98%E5%8C%96%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/">pytorch学习13-使用RNN优化流量预测</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-10-14/pytorch%E5%AD%A6%E4%B9%A012-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/">pytorch学习12-循环神经网络基础</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-10-09/pytorch%E5%AD%A6%E4%B9%A011-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/">pytorch学习11-卷积神经网络基础</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-30/pytorch%E5%AD%A6%E4%B9%A010-%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B%E5%AE%9E%E6%88%98/">pytorch学习10-流量预测实战</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-29/pytorch%E5%AD%A6%E4%B9%A09-%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/">pytorch学习9-多分类问题</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-27/pytorch%E5%AD%A6%E4%B9%A08-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/">pytorch学习8-加载数据集</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-26/pytorch%E5%AD%A6%E4%B9%A07-%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81%E7%9A%84%E8%BE%93%E5%85%A5/">pytorch学习7-处理多维特征的输入</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-23/pytorch%E5%AD%A6%E4%B9%A06-%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98Logistic%E5%9B%9E%E5%BD%92/">pytorch学习6-分类问题Logistic回归</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-22/pytorch%E5%AD%A6%E4%B9%A05-pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">pytorch学习5-pytorch实现线性回归</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-20/pytorch%E5%AD%A6%E4%B9%A03-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">pytorch学习3-梯度下降算法</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-15/pytorch%E5%AD%A6%E4%B9%A02-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/">pytorch学习2-线性模型</a>
                            </li>
                        
                            <li>
                                <a href="http://localhost:4000/2022-09-13/pytorch%E5%AD%A6%E4%B9%A01-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/">pytorch学习1-人工智能基础</a>
                            </li>
                        
                    
                </ul>
            </div>
        </div>
      </div>
    </div>
</div>
    </div>
    
    <div class="page-scrollTop" data-toggle="tooltip" data-placement="top" title="Top">
        <a href="javascript:void(0);">
            <div class="arrow"></div>
            <div class="stick"></div>
        </a>
    </div>
</div>

    <footer  class="footnote footnote-tiffany">
        <div class="container">
                <a class="foot-item" href="mailto:shurrik.dly@gmail.com" target="_blank"><span class="octicon octicon-mail"></span></a>
                <a class="foot-item" href="https://github.com/ixjx" target="_blank"><span class="octicon octicon-mark-github"></span></a>
                <a class="foot-item" href="http://localhost:4000/feed.xml" target="_blank"><span class="octicon octicon-rss"></span></a>
                <a class="foot-item" href="http://localhost:4000/link/"><span class="octicon octicon-link-external"></span></a>
                &nbsp;
                <a href="https://ixjx.github.io/"><span class="word-keep">&copy; Codeshurrik</span></a>
                <br>
                <span>珍爱生命，远离IE。请使用Chrome或Safari，你懂的 :)</span>
                <br>
                <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
                <script>// <![CDATA[
                    var now = new Date(); function createtime(){ var grt= new Date("07/28/2013 21:00:00");now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} document.getElementById("timeDate").innerHTML = "已安全运行"+dnum+"天"; document.getElementById("times").innerHTML = hnum + "小时" + mnum + "分" + snum + "秒"; } setInterval("createtime()",250);
                // ]]></script>
        </div>
    </footer>
    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script>
    <script type="text/javascript" src="https://cdn.bootcss.com/bootstrap/3.3.0/js/bootstrap.min.js"></script>
    <!-- <script id="MathJax-script" async src="https://cdn.bootcss.com/mathjax/3.0.5/es5/tex-mml-chtml.js"></script> -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    
    <script type="text/javascript" src="http://localhost:4000/static/js/script.js"></script>
    <script type="text/javascript" src="http://localhost:4000/static/js/post.js"></script>
    


</body>
</html>
